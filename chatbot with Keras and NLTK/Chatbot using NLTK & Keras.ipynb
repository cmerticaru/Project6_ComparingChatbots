{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Task Oriented Bot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this particular Machine Learning project I wanted to combine my interest as an aspiring Product Manager with my current work experience as a collections supervisor with the knowledge accumulated in the Machine learning module.\n",
    "Building a chatbot that is able to provide answers related to invoicing and payment questions seemed for me the best way to achieve this.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I started with putting the pseudo code together - how the interaction would look like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pseudo code chatbot\n",
    "1. User starts the conversation\n",
    "2. Chatbot has answers for a list of questions that can be asked on the topic of invoicing and payment options\n",
    "3. Chatbot has a slight capacity for correctly picking the right answer even when there are minor spelling mistakes\n",
    "4. Topics for which chatbot can provide answers: how to pay an invoice, where to find an invoice, how to change payment method, what to do when invoice is wrong.\n",
    "5. Chatbot is also able to recognize when user asks to be transferred to human agent to continue the conversation\n",
    "\n",
    "Next steps:\n",
    "1. Create the possibility for chatbot to initiate the conversation when user is logged on the page (proactivity)\n",
    "2. Create the possibility for the chatbot to recognize correct invoice numbers + gather details + generate case number when extra work is needed by another dept\n",
    "3. Create the possibility to have multiple interactions instead of just 1 to 1 question and answers.\n",
    "4. Create the possibility of asking for feedback and registering the feedback on the helpfulness of the answer provided by the chatbot (After each question ask Was the answer helpful? If yes chatbot asks \"Is there additional topics you need help with?\" if yes continue with the loop. If no chatbot Thank you for reaching out to us, have a great day!. If No after Was the answer helpful? Chatbot says Sorry to hear that, let me put you in contact with an agent that can help you further)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code used for this project is sourced from here\n",
    "https://data-flair.training/blogs/python-chatbot-project/\n",
    "\n",
    "https://dzone.com/articles/python-chatbot-project-build-your-first-python-pro\n",
    "\n",
    "https://www.datacamp.com/community/tutorials/building-a-chatbot-using-chatterbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install numpy==1.19.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the libraries necessary for the whole project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Merti\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Merti\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras #Tensorflow and Keras are used for the training of the chatbot\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D, Activation, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import random\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer #https://www.geeksforgeeks.org/python-lemmatization-with-nltk/#:~:text=Lemmatization%20is%20the%20process%20of,similar%20meaning%20to%20one%20word. Lemmatization is the process of grouping together the different inflected forms of a word so they can be analysed as a single item. Lemmatization is similar to stemming but it brings context to the words. So it links words with similar meaning to one word.\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "import json\n",
    "import pickle #https://docs.python.org/3/library/pickle.html The pickle module implements binary protocols for serializing and de-serializing a Python object structure. “Pickling” is the process whereby a Python object hierarchy is converted into a byte stream, and “unpickling” is the inverse operation, whereby a byte stream (from a binary file or bytes-like object) is converted back into an object hierarchy. Pickling (and unpickling) is alternatively known as “serialization”, “marshalling,” 1 or “flattening”; however, to avoid confusion, the terms used here are “pickling” and “unpickling”.\n",
    "import nltk\n",
    "nltk.download('punkt') #https://www.kite.com/python/docs/nltk.punkt Punkt Sentence Tokenizer This tokenizer divides a text into a list of sentences, by using an unsupervised algorithm to build a model for abbreviation words, collocations, and words that start sentences. It must be trained on a large collection of plaintext in the target language before it can be used. The NLTK data package includes a pre-trained Punkt tokenizer for English.\n",
    "import nltk\n",
    "nltk.download('wordnet') #https://www.tutorialspoint.com/how-to-get-synonyms-antonyms-from-nltk-wordnet-in-python#:~:text=The%20WordNet%20is%20a%20part,then%20download%20the%20WordNet%20package. The WordNet is a part of Python's Natural Language Toolkit. It is a large word database of English Nouns, Adjectives, Adverbs and Verbs. These are grouped into some set of cognitive synonyms, which are called synsets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the \"intents\" file in which we create the potential questions from the user and potential answers from the chatbot, where we have the following structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#tag - type of topic discussed \n",
    "#patterns - potential user input\n",
    "#responses - variation of possible chatbot responses which can be given based on the patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "intents_file = open('intents.json').read()\n",
    "intents = json.loads(intents_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first phase the potential questions from user (the patterns) are split, tokenized, linked to a tag (so there is a connection between the tag-topic and the pattern - user question). by printing documents we see this connection made between the tag and the pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['Hi'], 'greeting'), (['Hey'], 'greeting'), (['Is', 'anyone', 'there', '?'], 'greeting'), (['Hello'], 'greeting'), (['Hay'], 'greeting'), (['Good', 'morning'], 'greeting'), (['Good', 'day'], 'greeting'), (['Good', 'evening'], 'greeting'), (['Good', 'afternoon'], 'greeting'), (['Hiya'], 'greeting'), (['Bye'], 'goodbye'), (['See', 'you', 'later'], 'goodbye'), (['Goodbye'], 'goodbye'), (['Have', 'a', 'nice', 'day'], 'goodbye'), (['Have', 'a', 'great', 'day'], 'goodbye'), (['See', 'ya'], 'goodbye'), (['Later'], 'goodbye'), (['Thanks'], 'thanks'), (['Thank', 'you'], 'thanks'), (['That', \"'s\", 'helpful'], 'thanks'), (['Thanks', 'for', 'the', 'help'], 'thanks'), (['Who', 'are', 'you', '?'], 'name'), (['What', 'are', 'you', '?'], 'name'), (['Who', 'am', 'I', 'talking', 'to', '?'], 'name'), (['what', 'is', 'your', 'name'], 'name'), (['what', 'should', 'I', 'call', 'you'], 'name'), (['whats', 'your', 'name', '?'], 'name'), (['what', 'are', 'you', 'called'], 'name'), (['what', 'are', 'they', 'calling', 'you'], 'name'), (['Could', 'you', 'help', 'me', '?'], 'help'), (['give', 'me', 'a', 'hand', 'please'], 'help'), (['Can', 'you', 'help', '?'], 'help'), (['What', 'can', 'you', 'do', 'for', 'me', '?'], 'help'), (['I', 'need', 'support'], 'help'), (['I', 'need', 'help'], 'help'), (['support', 'me', 'please'], 'help'), (['help', 'me', 'please'], 'help'), (['help', 'me'], 'help'), (['I', 'need', 'some', 'help'], 'help'), (['I', 'have', 'a', 'problem'], 'help'), (['I', 'have', 'a', 'question'], 'help'), (['Can', 'you', 'help', 'me', 'with', 'something', '?'], 'help'), (['Can', 'you', 'give', 'me', 'some', 'advice'], 'help'), (['I', 'need', 'support'], 'help'), (['Could', 'you', 'please', 'help', 'me', 'solve', 'this', 'issue', '?'], 'help'), (['Something', \"'s\", 'not', 'right'], 'help'), (['Could', 'you', 'help', 'me', 'with', 'something', '?'], 'help'), (['Please', 'could', 'you', 'help', 'me', '?'], 'help'), (['I', 'have', 'an', 'outstanding', 'invoice', 'how', 'can', 'I', 'pay', 'it'], 'payinvoice'), (['I', 'have', 'an', 'overdue', 'invoice', 'how', 'can', 'I', 'pay', 'it'], 'payinvoice'), (['I', 'need', 'to', 'pay', 'my', 'overdue', 'invoice'], 'payinvoice'), (['I', 'need', 'to', 'pay', 'my', 'invoice'], 'payinvoice'), (['how', 'to', 'pay', 'my', 'invoice'], 'payinvoice'), (['I', 'want', 'to', 'pay', 'an', 'invoice'], 'payinvoice'), (['can', 'you', 'tell', 'me', 'how', 'to', 'pay', 'an', 'invoice'], 'payinvoice'), (['I', 'have', 'an', 'invoice', 'to', 'be', 'paid'], 'payinvoice'), (['I', 'have', 'to', 'pay', 'an', 'invoice'], 'payinvoice'), (['I', 'would', 'like', 'to', 'pay', 'my', 'last', 'invoice', ',', 'can', 'you', 'help', '?'], 'payinvoice'), (['Would', 'you', 'help', 'me', 'to', 'pay', 'my', 'invoice', '?'], 'payinvoice'), (['I', 'need', 'to', 'pay', 'my', 'invoice', ',', 'but', 'I', 'dont', 'know', 'how'], 'payinvoice'), (['I', 'can', 'not', 'pay', 'my', 'last', 'invoice', '.', 'Can', 'you', 'tell', 'me', 'how', '?'], 'payinvoice'), (['How', 'could', 'I', 'pay', 'my', 'last', 'invoice', ',', 'could', 'you', 'please', 'guide', 'me', 'through', 'the', 'steps', '?'], 'payinvoice'), (['How', 'can', 'I', 'pay', 'my', 'latest', 'invoice', '?'], 'payinvoice'), (['I', 'need', 'a', 'copy', 'of', 'my', 'invoice'], 'findinvoice'), (['I', 'want', 'a', 'copy', 'of', 'an', 'invoice'], 'findinvoice'), (['i', 'need', 'to', 'retrieve', 'an', 'invoice'], 'findinvoice'), (['i', 'want', 'to', 'download', 'an', 'invoice'], 'findinvoice'), (['i', 'want', 'to', 'access', 'an', 'invoice'], 'findinvoice'), (['can', 'I', 'obtain', 'a', 'copy', 'of', 'an', 'invoice'], 'findinvoice'), (['where', 'can', 'I', 'find', 'my', 'invoice'], 'findinvoice'), (['where', 'do', 'I', 'find', 'an', 'invoice'], 'findinvoice'), (['where', 'can', 'I', 'get', 'an', 'invoice'], 'findinvoice'), (['I', 'need', 'to', 'review', 'my', 'invoice'], 'findinvoice'), (['Please', 'provide', 'my', 'invoice'], 'findinvoice'), (['Can', 'you', 'give', 'me', 'my', 'invoice', '?'], 'findinvoice'), (['Can', 'I', 'have', 'a', 'pfd', 'of', 'my', 'invoice', '?'], 'findinvoice'), (['Could', 'you', 'please', 'email', 'me', 'my', 'invoice', '?'], 'findinvoice'), (['I', \"'ve\", 'lost', 'my', 'invoice'], 'findinvoice'), (['My', 'invoice', 'is', 'wrong'], 'wronginvoice'), (['My', 'invoice', 'is', 'wrong', ',', 'I', 'need', 'to', 'make', 'changes', 'before', 'I', 'can', 'pay'], 'wronginvoice'), (['invoice', 'is', 'not', 'correct'], 'wronginvoice'), (['the', 'invoice', 'is', 'incorrect'], 'wronginvoice'), (['can', 'i', 'get', 'the', 'invoice', 'corrected'], 'wronginvoice'), (['how', 'can', 'i', 'correct', 'my', 'invoice'], 'wronginvoice'), (['there', 'is', 'an', 'error', 'in', 'my', 'invoice', ',', 'how', 'can', 'I', 'correct', 'it'], 'wronginvoice'), (['how', 'to', 'amend', 'a', 'fault', 'in', 'the', 'invoice'], 'wronginvoice'), (['there', 'is', 'something', 'wrong', 'with', 'my', 'invoice', ',', 'how', 'can', 'I', 'get', 'it', 'corrected'], 'wronginvoice'), (['I', 'have', 'a', 'problem', 'with', 'my', 'invoice'], 'wronginvoice'), (['There', 'is', 'an', 'issue', 'with', 'my', 'invoice'], 'wronginvoice'), (['My', 'invoice', 'seems', 'to', 'be', 'incorrect'], 'wronginvoice'), (['My', 'invoice', 'does', 'not', 'make', 'sense'], 'wronginvoice'), (['I', 'got', 'an', 'invoice', 'that', 'does', 'not', 'belong', 'to', 'me'], 'wronginvoice'), (['This', 'invoice', 'is', 'not', 'correct'], 'wronginvoice'), (['Something', \"'s\", 'wrong', 'with', 'my', 'invoice'], 'wronginvoice'), (['Something', \"'s\", 'not', 'right', 'with', 'my', 'invoice'], 'wronginvoice'), (['Invoice', 'has', 'wrong', 'amount'], 'wronginvoiceamount'), (['Wrong', 'amount'], 'wronginvoiceamount'), (['invoice', 'amount', 'is', 'not', 'correct'], 'wronginvoiceamount'), (['amount', 'is', 'wrong'], 'wronginvoiceamount'), (['amount', 'is', 'incorrect'], 'wronginvoiceamount'), (['charge', 'is', 'incorrect'], 'wronginvoiceamount'), (['invoice', 'shows', 'wrong', 'amount', ',', 'how', 'can', 'I', 'correct', 'it'], 'wronginvoiceamount'), (['how', 'to', 'amend', 'the', 'wrong', 'amount'], 'wronginvoiceamount'), (['amount', 'charged', 'is', 'wrong'], 'wronginvoiceamount'), (['amount', 'charged', 'is', 'not', 'correct'], 'wronginvoiceamount'), (['Invoice', 'was', 'issued', 'with', 'wrong', 'price'], 'wronginvoiceamount'), (['invoice', 'has', 'wrong', 'rates'], 'wronginvoiceamount'), (['Prices', 'are', 'wrong', 'in', 'the', 'invoice'], 'wronginvoiceamount'), (['My', 'invoice', 'is', 'too', 'high'], 'wronginvoiceamount'), (['invoice', 'is', 'too', 'low'], 'wronginvoiceamount'), (['My', 'invoice', 'has', 'wrong', 'total'], 'wronginvoiceamount'), (['150', 'USD'], 'inputinvoiceamount'), (['100', 'EUR'], 'inputinvoiceamount'), (['23', 'GBP'], 'inputinvoiceamount'), (['11', 'JPY'], 'inputinvoiceamount'), (['10', 'AUD'], 'inputinvoiceamount'), (['98', 'CAD'], 'inputinvoiceamount'), (['56', 'CHF'], 'inputinvoiceamount'), (['75', 'CNY'], 'inputinvoiceamount'), (['23', 'SEK'], 'inputinvoiceamount'), (['1', 'NZD'], 'inputinvoiceamount'), (['200', 'RON'], 'inputinvoiceamount'), (['1500', 'RUB'], 'inputinvoiceamount'), (['10000', 'TRY'], 'inputinvoiceamount'), (['Invoice', 'has', 'wrong', 'details'], 'wronginvoicedetails'), (['Wrong', 'billing', 'details'], 'wronginvoicedetails'), (['billing', 'details', 'are', 'not', 'correct'], 'wronginvoicedetails'), (['billing', 'details', 'are', 'wrong'], 'wronginvoicedetails'), (['billing', 'details', 'are', 'incorrect'], 'wronginvoicedetails'), (['my', 'details', 'on', 'the', 'invoice', 'are', 'incorrect'], 'wronginvoicedetails'), (['invoice', 'shows', 'wrong', 'billing', 'details', ',', 'how', 'can', 'I', 'correct', 'it'], 'wronginvoicedetails'), (['how', 'to', 'amend', 'the', 'wrong', 'billing', 'details'], 'wronginvoicedetails'), (['billing', 'details', 'mentioned', 'on', 'the', 'invoice', 'are', 'wrong'], 'wronginvoicedetails'), (['billing', 'details', 'on', 'the', 'invoice', 'are', 'not', 'correct'], 'wronginvoicedetails'), (['My', 'billing', 'address', 'is', 'wrong', 'on', 'the', 'invoice'], 'wronginvoicedetails'), (['The', 'address', 'information', 'on', 'my', 'invoice', 'is', 'incorrect'], 'wronginvoicedetails'), (['The', 'billing', 'address', 'on', 'the', 'invoice', 'is', 'not', 'correct'], 'wronginvoicedetails'), (['The', 'billing', 'details', 'are', 'wrong', 'on', 'the', 'invoice'], 'wronginvoicedetails'), (['123', 'Revolutionary', 'Road', ',', 'Washington', ',', 'US'], 'inputinvoicedetails'), (['345', 'Main', 'Street', ',', 'Mississippi'], 'inputinvoicedetails'), (['300', 'Prinsengracht', ',', 'Amsterdam'], 'inputinvoicedetails'), (['12', 'Hobbit', 'Str', '.'], 'inputinvoicedetails'), (['Champs', 'Elysees', 'No', '2', ',', 'Paris'], 'inputinvoicedetails'), (['Baker', 'Street', '221b', ',', 'London'], 'inputinvoicedetails'), (['1600', 'Pennsylvania', 'Avenue', ',', 'Washington', 'DC', ',', 'USA'], 'inputinvoicedetails'), (['11', 'Wall', 'Street', 'New', 'York', ',', 'NY'], 'inputinvoicedetails'), (['350', 'Fifth', 'Avenue', 'New', 'York', ',', 'NY', '10118'], 'inputinvoicedetails'), (['4059', 'Mt', 'Lee', 'Dr.', 'Hollywood', ',', 'CA', '90068'], 'inputinvoicedetails'), (['Buckingham', 'Palace', ',', 'London', ',', 'England'], 'inputinvoicedetails'), (['Invoice', 'has', 'wrong', 'due', 'date'], 'wronginvoiceduedate'), (['Wrong', 'Due', 'Date'], 'wronginvoiceduedate'), (['due', 'date', 'is', 'not', 'correct'], 'wronginvoiceduedate'), (['due', 'date', 'is', 'wrong'], 'wronginvoiceduedate'), (['due', 'date', 'is', 'incorrect'], 'wronginvoiceduedate'), (['the', 'due', 'date', 'on', 'the', 'invoice', 'is', 'incorrect'], 'wronginvoiceduedate'), (['invoice', 'shows', 'wrong', 'due', 'date', ',', 'how', 'can', 'I', 'correct', 'it'], 'wronginvoiceduedate'), (['how', 'to', 'amend', 'the', 'wrong', 'due', 'date'], 'wronginvoiceduedate'), (['due', 'date', 'on', 'the', 'invoice', 'is', 'not', 'correct'], 'wronginvoiceduedate'), (['Invoice', 'was', 'issued', 'with', 'wrong', 'dates'], 'wronginvoiceduedate'), (['Dates', 'on', 'my', 'invoice', 'is', 'wrong'], 'wronginvoiceduedate'), (['The', 'date', 'on', 'my', 'invoice', 'does', 'not', 'make', 'sense'], 'wronginvoiceduedate'), (['The', 'date', 'of', 'my', 'invoice', 'is', 'in', 'the', 'past'], 'wronginvoiceduedate'), (['The', 'data', 'of', 'my', 'invoice', 'is', 'far', 'in', 'the', 'future'], 'wronginvoiceduedate'), (['There', 'is', 'no', 'date', 'on', 'this', 'invoice'], 'wronginvoiceduedate'), (['The', 'invoice', 'is', 'not', 'dated'], 'wronginvoiceduedate'), (['01.10.2020'], 'inputinvoiceduedate'), (['25.12.2020'], 'inputinvoiceduedate'), (['3rd', 'November'], 'inputinvoiceduedate'), (['5th', 'of', 'March'], 'inputinvoiceduedate'), (['January', '19th'], 'inputinvoiceduedate'), (['February', '28'], 'inputinvoiceduedate'), (['04.04'], 'inputinvoiceduedate'), (['21st', 'of', 'May'], 'inputinvoiceduedate'), (['15.06'], 'inputinvoiceduedate'), (['July', '18th'], 'inputinvoiceduedate'), (['17.08'], 'inputinvoiceduedate'), (['September', '11'], 'inputinvoiceduedate'), (['can', 'i', 'change', 'my', 'payment', 'method'], 'changepayment'), (['Wrong', 'payment', 'method'], 'changepayment'), (['i', 'want', 'to', 'change', 'the', 'way', 'i', 'pay', 'my', 'invoice'], 'changepayment'), (['how', 'can', 'i', 'change', 'my', 'payment', 'method'], 'changepayment'), (['i', 'want', 'a', 'different', 'payment', 'method'], 'changepayment'), (['what', 'payment', 'methods', 'are', 'available'], 'changepayment'), (['what', 'are', 'the', 'available', 'payment', 'methods'], 'changepayment'), (['how', 'to', 'select', 'a', 'different', 'payment', 'method'], 'changepayment'), (['how', 'can', 'I', 'change', 'the', 'payment', 'method', 'of', 'my', 'invoice'], 'changepayment'), (['I', 'would', 'like', 'to', 'change', 'my', 'payment', 'method'], 'changepayment'), (['I', 'need', 'to', 'change', 'my', 'payment', 'method'], 'changepayment'), (['Can', 'I', 'pay', 'differently', '?'], 'changepayment'), (['can', 'i', 'change', 'the', 'way', 'i', 'pay', 'my', 'bills'], 'changepayment'), (['can', 'i', 'change', 'how', 'i', 'pay'], 'changepayment'), (['Can', 'I', 'pay', 'with', 'card', '?'], 'changepayment'), (['can', 'I', 'pay', 'with', 'CC', '?'], 'changepayment'), (['can', 'i', 'pay', 'with', 'Cash', '?'], 'changepayment'), (['can', 'I', 'pay', 'with', 'Paypal', '?'], 'changepayment'), (['Could', 'I', 'change', 'my', 'payment', 'method', '?'], 'changepayment'), (['What', 'are', 'the', 'payment', 'options', '?'], 'changepayment'), (['What', 'are', 'my', 'payment', 'options', '?'], 'changepayment'), (['How', 'can', 'I', 'pay', '?'], 'changepayment'), (['i', 'want', 'to', 'talk', 'to', 'a', 'human', 'agent'], 'human'), (['need', 'to', 'talk', 'to', 'a', 'human'], 'human'), (['please', 'get', 'me', 'in', 'contact', 'with', 'a', 'human'], 'human'), (['dont', 'want', 'to', 'talk', 'to', 'you', 'anymore', ',', 'i', 'want', 'a', 'human', 'agent'], 'human'), (['you', 'can', 'not', 'help', 'me', 'i', 'want', 'to', 'talk', 'to', 'a', 'human', 'being'], 'human'), (['want', 'to', 'talk', 'to', 'a', 'person'], 'human'), (['i', 'need', 'a', 'person', 'to', 'help', 'me'], 'human'), (['please', 'get', 'me', 'a', 'human', 'agent'], 'human'), (['human', 'agent', 'please'], 'human'), (['Can', 'i', 'talk', 'to', 'a', 'real', 'person'], 'human'), (['real', 'person'], 'human'), (['human', 'being'], 'human'), (['Can', 'you', 'forward', 'me', 'to', 'an', 'actual', 'person'], 'human'), (['Could', 'I', 'please', 'talk', 'to', 'a', 'human', 'operator', '?'], 'human'), (['Could', 'you', 'please', 'transfer', 'my', 'call', 'to', 'a', 'human', 'operator', '?'], 'human')]\n"
     ]
    }
   ],
   "source": [
    "words=[]\n",
    "classes = []\n",
    "documents = []\n",
    "ignore_letters = ['!', '?', ',', '.']\n",
    "\n",
    "for intent in intents['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        #tokenize each word\n",
    "        word = nltk.word_tokenize(pattern)\n",
    "        words.extend(word)        \n",
    "        #add documents in the corpus\n",
    "        documents.append((word, intent['tag']))\n",
    "        # add to our classes list\n",
    "        if intent['tag'] not in classes:\n",
    "            classes.append(intent['tag'])\n",
    "\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 files words and classes are created based on the information from the lemmatization. the tags are turned into 13 classes. there are 112 unique lemmatized words based on the information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214 documents\n",
      "16 classes ['changepayment', 'findinvoice', 'goodbye', 'greeting', 'help', 'human', 'inputinvoiceamount', 'inputinvoicedetails', 'inputinvoiceduedate', 'name', 'payinvoice', 'thanks', 'wronginvoice', 'wronginvoiceamount', 'wronginvoicedetails', 'wronginvoiceduedate']\n",
      "258 unique lemmatized words [\"'s\", \"'ve\", '01.10.2020', '04.04', '1', '10', '100', '10000', '10118', '11', '12', '123', '15.06', '150', '1500', '1600', '17.08', '18th', '19th', '2', '200', '21st', '221b', '23', '25.12.2020', '28', '300', '345', '350', '3rd', '4059', '56', '5th', '75', '90068', '98', 'a', 'access', 'actual', 'address', 'advice', 'afternoon', 'agent', 'am', 'amend', 'amount', 'amsterdam', 'an', 'anymore', 'anyone', 'are', 'aud', 'available', 'avenue', 'baker', 'be', 'before', 'being', 'belong', 'bill', 'billing', 'buckingham', 'but', 'bye', 'ca', 'cad', 'call', 'called', 'calling', 'can', 'card', 'cash', 'cc', 'champ', 'change', 'charge', 'charged', 'chf', 'cny', 'contact', 'copy', 'correct', 'corrected', 'could', 'data', 'date', 'dated', 'day', 'dc', 'detail', 'different', 'differently', 'do', 'doe', 'dont', 'download', 'dr.', 'due', 'elysees', 'email', 'england', 'error', 'eur', 'evening', 'far', 'fault', 'february', 'fifth', 'find', 'for', 'forward', 'future', 'gbp', 'get', 'give', 'good', 'goodbye', 'got', 'great', 'guide', 'ha', 'hand', 'have', 'hay', 'hello', 'help', 'helpful', 'hey', 'hi', 'high', 'hiya', 'hobbit', 'hollywood', 'how', 'human', 'i', 'in', 'incorrect', 'information', 'invoice', 'is', 'issue', 'issued', 'it', 'january', 'jpy', 'july', 'know', 'last', 'later', 'latest', 'lee', 'like', 'london', 'lost', 'low', 'main', 'make', 'march', 'may', 'me', 'mentioned', 'method', 'mississippi', 'morning', 'mt', 'my', 'name', 'need', 'new', 'nice', 'no', 'not', 'november', 'ny', 'nzd', 'obtain', 'of', 'on', 'operator', 'option', 'outstanding', 'overdue', 'paid', 'palace', 'paris', 'past', 'pay', 'payment', 'paypal', 'pennsylvania', 'person', 'pfd', 'please', 'price', 'prinsengracht', 'problem', 'provide', 'question', 'rate', 'real', 'retrieve', 'review', 'revolutionary', 'right', 'road', 'ron', 'rub', 'see', 'seems', 'sek', 'select', 'sense', 'september', 'should', 'show', 'solve', 'some', 'something', 'step', 'str', 'street', 'support', 'talk', 'talking', 'tell', 'thank', 'thanks', 'that', 'the', 'there', 'they', 'this', 'through', 'to', 'too', 'total', 'transfer', 'try', 'u', 'usa', 'usd', 'wa', 'wall', 'want', 'washington', 'way', 'what', 'whats', 'where', 'who', 'with', 'would', 'wrong', 'ya', 'york', 'you', 'your']\n"
     ]
    }
   ],
   "source": [
    "# lemmatize and lower each word and remove duplicates\n",
    "words = [lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore_letters]\n",
    "words = sorted(list(set(words)))\n",
    "# sort classes\n",
    "classes = sorted(list(set(classes)))\n",
    "# documents = combination between patterns and intents\n",
    "print (len(documents), \"documents\")\n",
    "# classes = intents\n",
    "print (len(classes), \"classes\", classes)\n",
    "# words = all words, vocabulary\n",
    "print (len(words), \"unique lemmatized words\", words)\n",
    "pickle.dump(words,open('words.pkl','wb'))\n",
    "pickle.dump(classes,open('classes.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step the training data is created with the bag of words method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data is created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Merti\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    }
   ],
   "source": [
    "# create the training data\n",
    "training = []\n",
    "# create empty array for the output\n",
    "output_empty = [0] * len(classes)\n",
    "# training set, bag of words for every sentence\n",
    "for doc in documents:\n",
    "    # initializing bag of words\n",
    "    bag = []\n",
    "    # list of tokenized words for the pattern\n",
    "    word_patterns = doc[0]\n",
    "    # lemmatize each word - create base word, in attempt to represent related words\n",
    "    word_patterns = [lemmatizer.lemmatize(word.lower()) for word in word_patterns]\n",
    "    # create the bag of words array with 1, if word is found in current pattern\n",
    "    for word in words:\n",
    "        bag.append(1) if word in word_patterns else bag.append(0)\n",
    "\n",
    "    # output is a '0' for each tag and '1' for current tag (for each pattern)\n",
    "    output_row = list(output_empty)\n",
    "    output_row[classes.index(doc[1])] = 1\n",
    "    training.append([bag, output_row])\n",
    "# shuffle the features and make numpy array\n",
    "random.shuffle(training)\n",
    "training = np.array(training)\n",
    "# create training and testing lists. X - patterns, Y - intents\n",
    "train_x = list(training[:,0])\n",
    "train_y = list(training[:,1])\n",
    "print(\"Training data is created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the neural network model using the Sequential method. Sequential API is the easiest model to build and run in Keras. A sequential model allows us to create models layer by layer in a step by step fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "43/43 [==============================] - 0s 973us/step - loss: 2.7317 - accuracy: 0.0888\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 0s 953us/step - loss: 2.4568 - accuracy: 0.2383\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 0s 1000us/step - loss: 2.0884 - accuracy: 0.3738\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 1.7500 - accuracy: 0.4252\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - 0s 999us/step - loss: 1.4557 - accuracy: 0.5374\n",
      "Epoch 6/200\n",
      "43/43 [==============================] - 0s 1000us/step - loss: 1.3007 - accuracy: 0.5981\n",
      "Epoch 7/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 1.1423 - accuracy: 0.6402\n",
      "Epoch 8/200\n",
      "43/43 [==============================] - 0s 953us/step - loss: 1.0431 - accuracy: 0.6402\n",
      "Epoch 9/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.8308 - accuracy: 0.7617\n",
      "Epoch 10/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.7767 - accuracy: 0.7383\n",
      "Epoch 11/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.7830 - accuracy: 0.7523\n",
      "Epoch 12/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.6119 - accuracy: 0.8224\n",
      "Epoch 13/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.5608 - accuracy: 0.8692\n",
      "Epoch 14/200\n",
      "43/43 [==============================] - 0s 976us/step - loss: 0.5593 - accuracy: 0.8131\n",
      "Epoch 15/200\n",
      "43/43 [==============================] - 0s 953us/step - loss: 0.4479 - accuracy: 0.8645\n",
      "Epoch 16/200\n",
      "43/43 [==============================] - 0s 999us/step - loss: 0.4482 - accuracy: 0.8505\n",
      "Epoch 17/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3865 - accuracy: 0.8925\n",
      "Epoch 18/200\n",
      "43/43 [==============================] - 0s 999us/step - loss: 0.3628 - accuracy: 0.8738\n",
      "Epoch 19/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2859 - accuracy: 0.9346\n",
      "Epoch 20/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2570 - accuracy: 0.9439\n",
      "Epoch 21/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2892 - accuracy: 0.9393\n",
      "Epoch 22/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2799 - accuracy: 0.9019\n",
      "Epoch 23/200\n",
      "43/43 [==============================] - 0s 976us/step - loss: 0.1927 - accuracy: 0.9673\n",
      "Epoch 24/200\n",
      "43/43 [==============================] - 0s 953us/step - loss: 0.2137 - accuracy: 0.9439\n",
      "Epoch 25/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.1880 - accuracy: 0.9626\n",
      "Epoch 26/200\n",
      "43/43 [==============================] - 0s 953us/step - loss: 0.1815 - accuracy: 0.9673\n",
      "Epoch 27/200\n",
      "43/43 [==============================] - 0s 976us/step - loss: 0.1561 - accuracy: 0.9579\n",
      "Epoch 28/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.1473 - accuracy: 0.9533\n",
      "Epoch 29/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.1367 - accuracy: 0.9673\n",
      "Epoch 30/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.1388 - accuracy: 0.9720\n",
      "Epoch 31/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.0686 - accuracy: 0.9953\n",
      "Epoch 32/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.0974 - accuracy: 0.9720\n",
      "Epoch 33/200\n",
      "43/43 [==============================] - 0s 953us/step - loss: 0.0880 - accuracy: 0.9813\n",
      "Epoch 34/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.1144 - accuracy: 0.9626\n",
      "Epoch 35/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.1413 - accuracy: 0.9720\n",
      "Epoch 36/200\n",
      "43/43 [==============================] - 0s 976us/step - loss: 0.0860 - accuracy: 0.9813\n",
      "Epoch 37/200\n",
      "43/43 [==============================] - 0s 929us/step - loss: 0.0510 - accuracy: 1.0000\n",
      "Epoch 38/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.1097 - accuracy: 0.9673\n",
      "Epoch 39/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.0586 - accuracy: 0.9813\n",
      "Epoch 40/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.0900 - accuracy: 0.9626\n",
      "Epoch 41/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.0791 - accuracy: 0.9907\n",
      "Epoch 42/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.0845 - accuracy: 0.9673\n",
      "Epoch 43/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.0533 - accuracy: 0.9860\n",
      "Epoch 44/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.0747 - accuracy: 0.9766\n",
      "Epoch 45/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.0480 - accuracy: 0.9907\n",
      "Epoch 46/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.0419 - accuracy: 1.0000\n",
      "Epoch 47/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.0267 - accuracy: 0.9953\n",
      "Epoch 48/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.0412 - accuracy: 0.9907\n",
      "Epoch 49/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.0412 - accuracy: 0.9953\n",
      "Epoch 50/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.0403 - accuracy: 0.9860\n",
      "Epoch 51/200\n",
      "43/43 [==============================] - 0s 999us/step - loss: 0.0516 - accuracy: 0.9907\n",
      "Epoch 52/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.0391 - accuracy: 0.9953\n",
      "Epoch 53/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.0931 - accuracy: 0.9720\n",
      "Epoch 54/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.0597 - accuracy: 0.9813\n",
      "Epoch 55/200\n",
      "43/43 [==============================] - 0s 906us/step - loss: 0.0340 - accuracy: 0.9907\n",
      "Epoch 56/200\n",
      "43/43 [==============================] - 0s 837us/step - loss: 0.0336 - accuracy: 0.9953\n",
      "Epoch 57/200\n",
      "43/43 [==============================] - 0s 837us/step - loss: 0.0355 - accuracy: 0.9953\n",
      "Epoch 58/200\n",
      "43/43 [==============================] - 0s 860us/step - loss: 0.0396 - accuracy: 0.9907\n",
      "Epoch 59/200\n",
      "43/43 [==============================] - 0s 813us/step - loss: 0.0288 - accuracy: 0.9953\n",
      "Epoch 60/200\n",
      "43/43 [==============================] - 0s 883us/step - loss: 0.0297 - accuracy: 0.9953\n",
      "Epoch 61/200\n",
      "43/43 [==============================] - 0s 837us/step - loss: 0.0308 - accuracy: 1.0000\n",
      "Epoch 62/200\n",
      "43/43 [==============================] - 0s 907us/step - loss: 0.0226 - accuracy: 1.0000\n",
      "Epoch 63/200\n",
      "43/43 [==============================] - 0s 836us/step - loss: 0.0566 - accuracy: 0.9907\n",
      "Epoch 64/200\n",
      "43/43 [==============================] - 0s 883us/step - loss: 0.0135 - accuracy: 1.0000\n",
      "Epoch 65/200\n",
      "43/43 [==============================] - 0s 837us/step - loss: 0.0335 - accuracy: 0.9907\n",
      "Epoch 66/200\n",
      "43/43 [==============================] - 0s 837us/step - loss: 0.0305 - accuracy: 0.9907\n",
      "Epoch 67/200\n",
      "43/43 [==============================] - 0s 999us/step - loss: 0.0523 - accuracy: 0.9907\n",
      "Epoch 68/200\n",
      "43/43 [==============================] - 0s 883us/step - loss: 0.0317 - accuracy: 0.9907\n",
      "Epoch 69/200\n",
      "43/43 [==============================] - 0s 837us/step - loss: 0.0325 - accuracy: 0.9953\n",
      "Epoch 70/200\n",
      "43/43 [==============================] - 0s 814us/step - loss: 0.0224 - accuracy: 0.9953\n",
      "Epoch 71/200\n",
      "43/43 [==============================] - 0s 860us/step - loss: 0.0436 - accuracy: 0.9813\n",
      "Epoch 72/200\n",
      "43/43 [==============================] - 0s 813us/step - loss: 0.0195 - accuracy: 0.9953\n",
      "Epoch 73/200\n",
      "43/43 [==============================] - 0s 953us/step - loss: 0.0105 - accuracy: 1.0000\n",
      "Epoch 74/200\n",
      "43/43 [==============================] - 0s 907us/step - loss: 0.0409 - accuracy: 0.9953\n",
      "Epoch 75/200\n",
      "43/43 [==============================] - 0s 836us/step - loss: 0.0467 - accuracy: 0.9907\n",
      "Epoch 76/200\n",
      "43/43 [==============================] - 0s 837us/step - loss: 0.0279 - accuracy: 0.9953\n",
      "Epoch 77/200\n",
      "43/43 [==============================] - 0s 837us/step - loss: 0.0185 - accuracy: 1.0000\n",
      "Epoch 78/200\n",
      "43/43 [==============================] - 0s 906us/step - loss: 0.0163 - accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "43/43 [==============================] - 0s 953us/step - loss: 0.0267 - accuracy: 0.9953\n",
      "Epoch 80/200\n",
      "43/43 [==============================] - 0s 907us/step - loss: 0.0165 - accuracy: 1.0000\n",
      "Epoch 81/200\n",
      "43/43 [==============================] - 0s 883us/step - loss: 0.0138 - accuracy: 0.9953\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 860us/step - loss: 0.0468 - accuracy: 0.9860\n",
      "Epoch 83/200\n",
      "43/43 [==============================] - 0s 837us/step - loss: 0.0286 - accuracy: 0.9907\n",
      "Epoch 84/200\n",
      "43/43 [==============================] - 0s 790us/step - loss: 0.0256 - accuracy: 0.9953\n",
      "Epoch 85/200\n",
      "43/43 [==============================] - 0s 860us/step - loss: 0.0186 - accuracy: 0.9953\n",
      "Epoch 86/200\n",
      "43/43 [==============================] - 0s 814us/step - loss: 0.0267 - accuracy: 0.9907\n",
      "Epoch 87/200\n",
      "43/43 [==============================] - 0s 813us/step - loss: 0.0122 - accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "43/43 [==============================] - 0s 860us/step - loss: 0.0187 - accuracy: 0.9907\n",
      "Epoch 89/200\n",
      "43/43 [==============================] - 0s 860us/step - loss: 0.0181 - accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "43/43 [==============================] - 0s 813us/step - loss: 0.0204 - accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "43/43 [==============================] - 0s 837us/step - loss: 0.0264 - accuracy: 0.9907\n",
      "Epoch 92/200\n",
      "43/43 [==============================] - 0s 837us/step - loss: 0.0200 - accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "43/43 [==============================] - 0s 837us/step - loss: 0.0129 - accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "43/43 [==============================] - 0s 883us/step - loss: 0.0306 - accuracy: 0.9907\n",
      "Epoch 95/200\n",
      "43/43 [==============================] - 0s 813us/step - loss: 0.0261 - accuracy: 0.9953\n",
      "Epoch 96/200\n",
      "43/43 [==============================] - 0s 837us/step - loss: 0.0182 - accuracy: 0.9953\n",
      "Epoch 97/200\n",
      "43/43 [==============================] - 0s 930us/step - loss: 0.0140 - accuracy: 0.9953\n",
      "Epoch 98/200\n",
      "43/43 [==============================] - 0s 837us/step - loss: 0.0228 - accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "43/43 [==============================] - 0s 860us/step - loss: 0.0118 - accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "43/43 [==============================] - 0s 813us/step - loss: 0.0240 - accuracy: 0.9907\n",
      "Epoch 101/200\n",
      "43/43 [==============================] - 0s 813us/step - loss: 0.0107 - accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "43/43 [==============================] - 0s 883us/step - loss: 0.0150 - accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "43/43 [==============================] - 0s 813us/step - loss: 0.0574 - accuracy: 0.9860\n",
      "Epoch 104/200\n",
      "43/43 [==============================] - 0s 837us/step - loss: 0.0130 - accuracy: 0.9953\n",
      "Epoch 105/200\n",
      "43/43 [==============================] - 0s 930us/step - loss: 0.0345 - accuracy: 0.9953\n",
      "Epoch 106/200\n",
      "43/43 [==============================] - 0s 930us/step - loss: 0.0143 - accuracy: 0.9953\n",
      "Epoch 107/200\n",
      "43/43 [==============================] - 0s 813us/step - loss: 0.0125 - accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "43/43 [==============================] - 0s 813us/step - loss: 0.0276 - accuracy: 0.9953\n",
      "Epoch 109/200\n",
      "43/43 [==============================] - 0s 814us/step - loss: 0.0197 - accuracy: 0.9953\n",
      "Epoch 110/200\n",
      "43/43 [==============================] - 0s 860us/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "43/43 [==============================] - 0s 814us/step - loss: 0.0119 - accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "43/43 [==============================] - 0s 837us/step - loss: 0.0213 - accuracy: 0.9907\n",
      "Epoch 113/200\n",
      "43/43 [==============================] - 0s 883us/step - loss: 0.0468 - accuracy: 0.9860\n",
      "Epoch 114/200\n",
      "43/43 [==============================] - 0s 837us/step - loss: 0.0115 - accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "43/43 [==============================] - 0s 837us/step - loss: 0.0201 - accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "43/43 [==============================] - 0s 837us/step - loss: 0.0087 - accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "43/43 [==============================] - 0s 906us/step - loss: 0.0211 - accuracy: 0.9953\n",
      "Epoch 118/200\n",
      "43/43 [==============================] - 0s 813us/step - loss: 0.0125 - accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "43/43 [==============================] - 0s 814us/step - loss: 0.0135 - accuracy: 0.9953\n",
      "Epoch 120/200\n",
      "43/43 [==============================] - 0s 837us/step - loss: 0.0132 - accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "43/43 [==============================] - 0s 814us/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "43/43 [==============================] - 0s 907us/step - loss: 0.0096 - accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "43/43 [==============================] - 0s 814us/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "43/43 [==============================] - 0s 814us/step - loss: 0.0116 - accuracy: 0.9953\n",
      "Epoch 125/200\n",
      "43/43 [==============================] - 0s 883us/step - loss: 0.0281 - accuracy: 0.9953\n",
      "Epoch 126/200\n",
      "43/43 [==============================] - 0s 837us/step - loss: 0.0104 - accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "43/43 [==============================] - 0s 837us/step - loss: 0.0130 - accuracy: 0.9953\n",
      "Epoch 128/200\n",
      "43/43 [==============================] - 0s 883us/step - loss: 0.0226 - accuracy: 0.9907\n",
      "Epoch 129/200\n",
      "43/43 [==============================] - 0s 813us/step - loss: 0.0117 - accuracy: 0.9953\n",
      "Epoch 130/200\n",
      "43/43 [==============================] - 0s 883us/step - loss: 0.0237 - accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "43/43 [==============================] - 0s 883us/step - loss: 0.0183 - accuracy: 0.9907\n",
      "Epoch 132/200\n",
      "43/43 [==============================] - 0s 813us/step - loss: 0.0170 - accuracy: 0.9953\n",
      "Epoch 133/200\n",
      "43/43 [==============================] - 0s 814us/step - loss: 0.0073 - accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "43/43 [==============================] - 0s 837us/step - loss: 0.0228 - accuracy: 0.9953\n",
      "Epoch 135/200\n",
      "43/43 [==============================] - 0s 837us/step - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "43/43 [==============================] - 0s 906us/step - loss: 0.0160 - accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "43/43 [==============================] - 0s 883us/step - loss: 0.0119 - accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "43/43 [==============================] - 0s 860us/step - loss: 0.0448 - accuracy: 0.9907\n",
      "Epoch 139/200\n",
      "43/43 [==============================] - 0s 837us/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "43/43 [==============================] - 0s 907us/step - loss: 0.0120 - accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "43/43 [==============================] - 0s 837us/step - loss: 0.0113 - accuracy: 0.9953\n",
      "Epoch 142/200\n",
      "43/43 [==============================] - 0s 837us/step - loss: 0.0107 - accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "43/43 [==============================] - 0s 860us/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "43/43 [==============================] - 0s 836us/step - loss: 0.0088 - accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "43/43 [==============================] - 0s 883us/step - loss: 0.0082 - accuracy: 0.9953\n",
      "Epoch 146/200\n",
      "43/43 [==============================] - 0s 860us/step - loss: 0.0095 - accuracy: 0.9953\n",
      "Epoch 147/200\n",
      "43/43 [==============================] - 0s 883us/step - loss: 0.0168 - accuracy: 0.9953\n",
      "Epoch 148/200\n",
      "43/43 [==============================] - 0s 860us/step - loss: 0.0125 - accuracy: 0.9953\n",
      "Epoch 149/200\n",
      "43/43 [==============================] - 0s 837us/step - loss: 0.0244 - accuracy: 0.9907\n",
      "Epoch 150/200\n",
      "43/43 [==============================] - 0s 860us/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "43/43 [==============================] - 0s 837us/step - loss: 0.0174 - accuracy: 0.9953\n",
      "Epoch 152/200\n",
      "43/43 [==============================] - 0s 860us/step - loss: 0.0213 - accuracy: 0.9953\n",
      "Epoch 153/200\n",
      "43/43 [==============================] - 0s 836us/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "43/43 [==============================] - 0s 860us/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "43/43 [==============================] - 0s 813us/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "43/43 [==============================] - 0s 860us/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "43/43 [==============================] - 0s 883us/step - loss: 0.0169 - accuracy: 0.9953\n",
      "Epoch 158/200\n",
      "43/43 [==============================] - 0s 883us/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "43/43 [==============================] - 0s 883us/step - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "43/43 [==============================] - 0s 907us/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 907us/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "43/43 [==============================] - 0s 906us/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "43/43 [==============================] - 0s 860us/step - loss: 0.0117 - accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "43/43 [==============================] - 0s 813us/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "43/43 [==============================] - 0s 813us/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "43/43 [==============================] - 0s 860us/step - loss: 0.0098 - accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "43/43 [==============================] - 0s 837us/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "43/43 [==============================] - 0s 906us/step - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "43/43 [==============================] - 0s 837us/step - loss: 0.0092 - accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "43/43 [==============================] - 0s 837us/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "43/43 [==============================] - 0s 813us/step - loss: 0.0227 - accuracy: 0.9907\n",
      "Epoch 172/200\n",
      "43/43 [==============================] - 0s 837us/step - loss: 0.0105 - accuracy: 0.9953\n",
      "Epoch 173/200\n",
      "43/43 [==============================] - 0s 860us/step - loss: 0.0140 - accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "43/43 [==============================] - 0s 860us/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "43/43 [==============================] - 0s 860us/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "43/43 [==============================] - 0s 883us/step - loss: 0.0142 - accuracy: 0.9953\n",
      "Epoch 177/200\n",
      "43/43 [==============================] - 0s 953us/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "43/43 [==============================] - 0s 883us/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "43/43 [==============================] - 0s 907us/step - loss: 0.0127 - accuracy: 0.9953\n",
      "Epoch 180/200\n",
      "43/43 [==============================] - 0s 883us/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "43/43 [==============================] - 0s 883us/step - loss: 0.0212 - accuracy: 0.9953\n",
      "Epoch 182/200\n",
      "43/43 [==============================] - 0s 906us/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "43/43 [==============================] - 0s 837us/step - loss: 0.0092 - accuracy: 0.9953\n",
      "Epoch 184/200\n",
      "43/43 [==============================] - 0s 883us/step - loss: 0.0353 - accuracy: 0.9907\n",
      "Epoch 185/200\n",
      "43/43 [==============================] - 0s 813us/step - loss: 0.0366 - accuracy: 0.9953\n",
      "Epoch 186/200\n",
      "43/43 [==============================] - 0s 883us/step - loss: 0.0184 - accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "43/43 [==============================] - 0s 814us/step - loss: 0.0260 - accuracy: 0.9907\n",
      "Epoch 188/200\n",
      "43/43 [==============================] - 0s 883us/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "43/43 [==============================] - 0s 836us/step - loss: 0.0093 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "43/43 [==============================] - 0s 860us/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "43/43 [==============================] - 0s 930us/step - loss: 0.0231 - accuracy: 0.9907\n",
      "Epoch 192/200\n",
      "43/43 [==============================] - 0s 860us/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "43/43 [==============================] - 0s 930us/step - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "43/43 [==============================] - 0s 883us/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "43/43 [==============================] - 0s 837us/step - loss: 0.0096 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "43/43 [==============================] - 0s 930us/step - loss: 0.0077 - accuracy: 0.9953\n",
      "Epoch 197/200\n",
      "43/43 [==============================] - 0s 883us/step - loss: 0.0088 - accuracy: 0.9953\n",
      "Epoch 198/200\n",
      "43/43 [==============================] - 0s 883us/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "43/43 [==============================] - 0s 930us/step - loss: 0.0189 - accuracy: 0.9907\n",
      "model is created\n"
     ]
    }
   ],
   "source": [
    "# deep neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(200, input_shape=(len(train_x[0]),), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(train_y[0]), activation='softmax'))\n",
    "\n",
    "# Compiling model. SGD with Nesterov accelerated gradient gives good results for this model\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "#Training and saving the model \n",
    "hist = model.fit(np.array(train_x), np.array(train_y), epochs=200, batch_size=5, verbose=1)\n",
    "model.save('chatbot_model.h5', hist)\n",
    "\n",
    "print(\"model is created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can also check the model summary to see how many parameters were trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 200)               51800     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1616      \n",
      "=================================================================\n",
      "Total params: 73,516\n",
      "Trainable params: 73,516\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tf-nightly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step we load the model trained and created previously, as well as the intents file, the words and classes file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('chatbot_model.h5')\n",
    "intents = json.loads(open('intents.json').read())\n",
    "words = pickle.load(open('words.pkl','rb'))\n",
    "classes = pickle.load(open('classes.pkl','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create the functions pipeline for the chatbot activity:\n",
    "    1. sentences inputted by the user are cleaned up, tokenized, reduced to base form\n",
    "    2. cleaned sentences are turned into bag of words\n",
    "    3. based on the bag of words a function is predicting in which of the 13 classes the user sentence needs to be placed\n",
    "    4. another function is creating a randomization of retrieving one of the response answers based on the tags\n",
    "    5. last function is making the connection between the user input and the answer the chatbot retrieves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_sentence(sentence):\n",
    "    # tokenize the pattern - splitting words into array\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    # stemming every word - reducing to base form\n",
    "    sentence_words = [lemmatizer.lemmatize(word.lower()) for word in sentence_words]\n",
    "    return sentence_words\n",
    "\n",
    "# return bag of words array: 0 or 1 for words that exist in sentence\n",
    "def bag_of_words(sentence, words, show_details=True):\n",
    "    # tokenizing patterns\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "    # bag of words - vocabulary matrix\n",
    "    bag = [0]*len(words)  \n",
    "    for s in sentence_words:\n",
    "        for i,word in enumerate(words):\n",
    "            if word == s: \n",
    "                # assign 1 if current word is in the vocabulary position\n",
    "                bag[i] = 1\n",
    "                if show_details:\n",
    "                    print (\"found in bag: %s\" % word)\n",
    "    return(np.array(bag))\n",
    "def predict_class(sentence):\n",
    "    # filter below  threshold predictions\n",
    "    p = bag_of_words(sentence, words,show_details=False)\n",
    "    res = model.predict(np.array([p]))[0]\n",
    "    ERROR_THRESHOLD = 0.25\n",
    "    results = [[i,r] for i,r in enumerate(res) if r>ERROR_THRESHOLD]\n",
    "    # sorting strength probability\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return_list = []\n",
    "    for r in results:\n",
    "        return_list.append({\"intent\": classes[r[0]], \"probability\": str(r[1])})\n",
    "    return return_list\n",
    "\n",
    "def getResponse(ints, intents_json):\n",
    "    tag = ints[0]['intent']\n",
    "    list_of_intents = intents_json['intents']\n",
    "    for i in list_of_intents:\n",
    "        if(i['tag']== tag):\n",
    "            result = random.choice(i['responses'])\n",
    "            break\n",
    "    return result\n",
    "def chatbot_response(text):\n",
    "    ints = predict_class(text, model)\n",
    "    res = getResponse(ints, intents)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This last step is simply to create the interface for interaction with the chatbot in a nice environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating tkinter GUI\n",
    "import tkinter\n",
    "from tkinter import *\n",
    "\n",
    "\n",
    "def send():\n",
    "    msg = EntryBox.get(\"1.0\",'end-1c').strip()\n",
    "    EntryBox.delete(\"0.0\",END)\n",
    "    if msg != '':\n",
    "        ChatBox.config(state=NORMAL)\n",
    "        ChatBox.insert(END, \"You: \" + msg + '\\n\\n')\n",
    "        ChatBox.config(foreground=\"#446665\", font=(\"Verdana\", 12 )) \n",
    "        ints = predict_class(msg)\n",
    "        res = getResponse(ints, intents)\n",
    "        ChatBox.insert(END, \"Fin: \" + res + '\\n\\n')           \n",
    "        ChatBox.config(state=DISABLED)\n",
    "        ChatBox.yview(END)\n",
    "\n",
    "root = Tk()\n",
    "root.title(\"Fin the Finance Assistance Chatbot\")\n",
    "root.geometry(\"400x500\")\n",
    "root.resizable(width=FALSE, height=FALSE)\n",
    "\n",
    "#Create Chat window\n",
    "ChatBox = Text(root, bd=0, bg=\"white\", height=\"8\", width=\"60\", font=\"Arial\",)\n",
    "ChatBox.config(state=DISABLED)\n",
    "\n",
    "#Bind scrollbar to Chat window\n",
    "\n",
    "scrollbar = Scrollbar(root, command=ChatBox.yview, cursor=\"double_arrow\")\n",
    "ChatBox['yscrollcommand'] = scrollbar.set\n",
    "\n",
    "#Create Button to send message\n",
    "\n",
    "SendButton = Button(root, font=(\"Verdana\",12,'bold'), text=\"Send\", width=\"12\", height=5,\n",
    "                    bd=0, bg=\"#f9a602\", activebackground=\"#3c9d9b\",fg='#000000',\n",
    "                    command= send )\n",
    "\n",
    "#Create the box to enter message\n",
    "\n",
    "EntryBox = Text(root, bd=0, bg=\"white\",width=\"29\", height=\"5\", font=\"Arial\")\n",
    "\n",
    "#EntryBox.bind(\"<Return>\", send)\n",
    "\n",
    "#Place all components on the screen\n",
    "scrollbar.place(x=376,y=6, height=386)\n",
    "ChatBox.place(x=6,y=6, height=386, width=370)\n",
    "EntryBox.place(x=128, y=401, height=90, width=265)\n",
    "SendButton.place(x=6, y=401, height=90)\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python train_chatbot.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python chatgui.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The final step is to test the accuracy of the answers given by the chatbot. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With a score of 9 correct answers from 12 questions (Sample as below), we can consider this a fairly reliable chatbot for the task. We need to further test it with additional users and additional scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You: hei good evening\n",
    "\n",
    "Correct Fin: Hi, I am Fin, your Finance assistant chatbot, how can I help you today?\n",
    "\n",
    "You: lets see if you can help as my invoice is incorrect\n",
    "\n",
    "Correct Fin: I am sorry you consider your invoice to be incorrect. Can you let me know which of these areas is incorrect:Wrong amount/Wrong Billing Details/Wrong Due Date)\n",
    "\n",
    "You: the amount on the invoice is wrong\n",
    "\n",
    "Correct Fin: It seems you think the amount of the invoice is wrong. Please mention the invoice number, amount you think should have been charged and the reason why and I will open a case for our Finance Department to come back to you in the shortest time)\n",
    "\n",
    "You: ok this is great thank you have a nice day\n",
    "\n",
    "Correct Fin: Have a nice day! Before you go, do not forget to check the details for the recommended automated payment methods (link)\n",
    "\n",
    "You: there is something else. i need to know what are my payment options\n",
    "\n",
    "Wrong Fin: The available payment methods are credit card, bank transfer and automated payment. You can change your payment method here ...\n",
    "\n",
    "You: perfect this helps\n",
    "\n",
    "Wrong Fin: Yes please tell me your problem so I can assist you\n",
    "\n",
    "You: i do not need any other support. thank you very much\n",
    "\n",
    "Wrong Fin: Yes please tell me your problem so I can assist you\n",
    "\n",
    "You: thank you! have a great day\n",
    "\n",
    "Correct Fin: Have a nice day! Before you go, do not forget to check the details for the recommended automated payment methods (link)\n",
    "\n",
    "You: where can i retrieve a copy of my invoice\n",
    "\n",
    "Correct Fin: You can find a copy of your invoice by accessing this path ...\n",
    "\n",
    "You: and how can i pay this invoice\n",
    "\n",
    "Correct Fin: The available payment methods are credit card, bank transfer and automated payment. You can process payments from here ...\n",
    "\n",
    "You: aha and what if i want to change the payment method?\n",
    "\n",
    "Correct Fin: The available payment methods are credit card, bank transfer and automated payment. You can change your payment method here ...\n",
    "\n",
    "You: this is helpful thanks\n",
    "\n",
    "Correct Fin: Great to hear I could be of help! Before you go, do not forget to check the details for the recommended automated payment methods (link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another scenario tested is when certain words are mispelled, in 6 out of 8 tests even with typos the chatbot still provides the right answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You: how can i pay my otstanding invoice\n",
    "\n",
    "Correct Fin: The available payment methods are credit card, bank transfer and automated payment. You can process payments from here ...\n",
    "\n",
    "You: i need a cpy of my invoice\n",
    "\n",
    "Correct Fin: You can find a copy of your invoice by accessing this path ...\n",
    "\n",
    "You: my invice is wrong\n",
    "\n",
    "Correct Fin: I am sorry you consider your invoice to be incorrect. Can you let me know which of these areas is incorrect:Wrong amount/Wrong Billing Details/Wrong Due Date)\n",
    "\n",
    "You: payment mthod to be changed\n",
    "\n",
    "Correct Fin: The available payment methods are credit card, bank transfer and automated payment. You can change your payment method here ...\n",
    "\n",
    "You: please get me a hman agent\n",
    "\n",
    "Correct Fin: Sorry to hear I cannot help you, let me connect you with a human agent. Have a nice day!\n",
    "\n",
    "You: amont is wrng\n",
    "\n",
    "Wrong Fin: Hello, I am Fin, your Finance assistant chatbot, how can I help you today?\n",
    "\n",
    "You: billng detals is incorrect\n",
    "\n",
    "Wrong Fin: It seems you think the amount of the invoice is wrong. Please mention the invoice number, amount you think should have been charged and the reason why and I will open a case for our Finance Department to come back to you in the shortest time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to improve accuracy, further testing is needed to be done by additional users to account for cultural differences and different types of approaches when asking questions, and the input to be reintegrated in the intents file.\n",
    "\n",
    "Next step is also to create more complexity in the discussion with the chatbot, allowing for more than just 1 to 1 question and answers, and allowing the chatbot to follow up or ask additional clarifying questions.\n",
    "\n",
    "Another potential improvement is to allow the chatbot to initiate conversation when the user is on the page, which increases the proactivity and user experience.\n",
    "\n",
    "And another important improvement would be to ask for feedback on the answer to each question and quantify the feedback in order to improve the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using Keras on TensorFlow and NLTK libraries, having a detailed intents file used for training the model, having a low loss and high accuracy after the training, has allowed for the creation of a reliable task based chatbot that can correctly answer with high confidence on a restricted number of preset topics.\n",
    "\n",
    "For the purpose of this task based chatbot using Keras and NLTK is a good choice. For the future an idea would be to explore other methods and compare accuracy in order to understand if chatbot can be improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
